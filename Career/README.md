# Xinhe (Charles) Liu Introduction

- [Xinhe (Charles) Liu Introduction](#xinhe-charles-liu-introduction)
  - [Introduction](#introduction)
    - [Personal](#personal)
    - [Work Experience (Overview)](#work-experience-overview)
    - [Education](#education)
  - [ByteDance Experience](#bytedance-experience)
    - [Job Description](#job-description)
    - [Data Privacy](#data-privacy)
      - [IOS & TF Learning (Deep Learning System)](#ios--tf-learning-deep-learning-system)
    - [Ads Strategies](#ads-strategies)
      - [Eco System](#eco-system)
    - [Ads Ranking Optimization](#ads-ranking-optimization)
    - [Auction & Bidding](#auction--bidding)
    - [Online Experiments & Causal Machine Learning](#online-experiments--causal-machine-learning)
    - [Other Projects: Creative Solutions](#other-projects-creative-solutions)
  - [Goldman Sachs Experience](#goldman-sachs-experience)
    - [Job Description](#job-description-1)
    - [Factor Investing Strategies](#factor-investing-strategies)
    - [Volatility Trading Strateiges](#volatility-trading-strateiges)
    - [Data Analysis & Machine Learning Projects](#data-analysis--machine-learning-projects)
    - [Quantitative Developments](#quantitative-developments)
  - [Earlier Experiences (Internships & Projects)](#earlier-experiences-internships--projects)

## Introduction

### Personal

### Work Experience (Overview)

### Education

## ByteDance Experience

### Job Description

### Data Privacy

#### IOS & TF Learning (Deep Learning System) 

### Ads Strategies

    * Predictive modeling：提前识别vs假设检验 （predictive, explain, simulation )  
    * cold Start: Bandit & RF Learning 
    * 掉量：DML + Anomaly Detection

#### Eco System

    * ColdStart Ads head room
        * Debias & RF Learning 
    * 投放2.0  生态和长期价值

### Ads Ranking Optimization

    * AA Variance
    * Measurement Framework
    * Model, Module online & Offline Metrics
        * Counterfactual Metrics

### Auction & Bidding

    * 机制设计
    * 穿山甲一价计费 & 《合适》 & Google 第三方RTB流量上切一价（auction；bidding，etc） 

### Online Experiments & Causal Machine Learning 

> Reference Linxia Ren

### Other Projects: Creative Solutions

    * 归因，uplift modeling（推断uplift；开发frmework） 
    * Black-litterman for 预算分配 Optimization

## Goldman Sachs Experience

### Job Description

### Factor Investing Strategies

• Quantitative Investing Strategies: Created cutting-edge Alternative Risk Premia and Quantitative Investing index products. Built GS Cross-Asset Risk Premia Flagships (2018, 2020) which is the first cross-asset index product with multi-level optimization modules that combines different single asset factor strategies. (Sharpe 1.5, correlation < 0.4 for vs. all asset-class benchmarks).

• Quantitative Research & Analysis: Research projects around factor investing and quantitative asset managements. eg. Factor Crowding, Factor Timing Analyses: Used methods like multi-factor analysis, time-series analysis, cross validation to develop measures and analytics of crowdness. Leveraged different quantitative tools such as nowcasting, latent models & Bayesian inference and Kalman Filters to analyze the challenge of timing under the context of simulated multi-strategy portfolios.

### Volatility Trading Strateiges

• Volatility Trading Strategies: Developed the largest volatility products matrix and platform among all competitors. Developed the first systematic dispersion product with >100 names (2018), and first Volatility Carry strategies with shorted-dated weekly options and CDX-VIX relative value strategies (2019) Optimized strategy performance up to 2.5 Sharpe and correlation close to 0.


### Data Analysis & Machine Learning Projects

• Data Analysis/Outlier Analysis: Created anomaly detection system for 10000+ data streams consumed by STS index products, use Linear Models and Time Series Models for price data and hybrid and proximity based models for multi-level data to achieve an AUC close to 0.9. (2019) The model was extended to more complex intra-day data analysis models (frequency, latent variables).

• Machine Learning: Explored the usage of machine learning techniques on option hedging (reinforcement learning, improved cVar 20% in simulation) and backtesting (cross-validation with embargo, discounted measures, hyper parameters tuning to avoid overfit).

### Quantitative Developments

• Quantitative Analysis Services: Designed and productized quantitative modeling, analysis and analytics to clients. Cooperated with front-end teams to enhance reporting framework and provide new services such as internal backtesting and factor model (Axioma) APIs. Created the first comprehensive framework of Defensiveness that combines enhanced beta strategies with traditional hedging products that reduces hedging cost by 20%-60%.

• Backtesting & Pricing System Design: Lead the project of building a new calculation and backtesting system that combines real- time data and index calculation modules to give T+0 and real-time estimates of index levels, improved data availability by 8+ hours
and reduced support window by 40%.

## Earlier Experiences (Internships & Projects)

Summer Analyst, Flow Vol Desk Strat, Global Markets 6/17-8/17
• Modeling: Built data pipeline to mine desk trading flow and holding data with counterparties.(Python/R).


• AI System - AI detection and classification Pipeline: Built AI SaaS application to digitize offline retail data(sensor data to Stock Keeping Units(SKU), China) to automate store stocking and boost sales. Used Retina Net and ResNet to detect and classify objects, OpenCV to visualize and deploy in an web application or docker containers with offline batch prediction accuracy of 80%.

• Machine Learning - Portfolio Optimization with Hierarchical Risk Parity: Modeled the correlation matrix, a fully connected graph, as a tree using the clustering algorithm. Allocate optimal portfolio weights using a recursive bisection algorithm. Reduce variance by 42% (relatively) to Markowitz and 29% to Risk Parity in simulation results.

• Data Mining - Information Leakage and Stock Market: Worked on NYC taxi dataset to analyze the potential information leakage before the FOMC meeting. Utilized Python dashboard to visualize the geographical data. Tested the significance of information leakage. Applied predictive models (e.g. Poisson regression) to analyze the pick-ups and drop-offs data.
